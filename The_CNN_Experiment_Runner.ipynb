{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTNdIpvOSQRB"
      },
      "source": [
        "# Setup Experiments [ Models, Epochs ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHReJvS4S9yG"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import h5py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# dictionary of headless model of different architectures to be used for feature extraction\n",
        "\n",
        "# all from tfhub.dev \n",
        "\n",
        "EPOCHS = 3\n",
        "\n",
        "BATCH_SIZE_LIST = [\"32\", \"48\", \"64\"]\n",
        "\n",
        "models = {\n",
        "    \n",
        "    \"efficientnet\": (\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\", (224,224)),\n",
        "    \"efficientnet_v2\": (\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\", (224,224)),\n",
        "                     \"\"\n",
        "    \"mobilenet_v2\": (\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", (224,224)),\n",
        "    \"mobilenet_v3\": (\"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\", (224,224)),\n",
        "\n",
        "    \"inception_v1\":(\"https://tfhub.dev/google/imagenet/inception_v1/feature_vector/5\", (224,224)),\n",
        "    \"inception_v2\":(\"https://tfhub.dev/google/imagenet/inception_v2/feature_vector/5\", (224,224)),\n",
        "\n",
        "    \"inception_v3_inaturalist\":(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5\", (299,299)), # trained on iNaturalist dataset\n",
        "    \"inception_v3_imagenet\": (\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5\", (299,299)),\n",
        "\n",
        "    \"inception_resnet_v2\": (\"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/5\", (299,299)),\n",
        "\n",
        "\n",
        "    \"resnet_v2\": (\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\", (224,224))\n",
        "\n",
        "}\n",
        "\n",
        "for model in models:\n",
        "\n",
        "  print(f\"{model} url --> {models.get(model)[0]} || image size --> {models.get(model)[1]}\")"
      ],
      "metadata": {
        "id": "VSgh_8VcZON5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading The Data"
      ],
      "metadata": {
        "id": "tbTbbJ3QmNxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR7KggyST3tG"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive and get data\n",
        "from google.colab import drive\n",
        "import pathlib\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "# ^--- paint to where images are"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnU2pARGdSMV"
      },
      "outputs": [],
      "source": [
        "# Declare some values\n",
        "\n",
        "train_path = './image_data/train'\n",
        "valid_path = './image_data/val'\n",
        "test_path = './image_data/test'\n",
        "\n",
        "# ^-- point to proper directory \n",
        "\n",
        "IMAGE_SIZE = () # <-- variable initionlization only"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to make plots and save\n",
        "\n",
        "def plot_acc(model,dir):\n",
        "  \n",
        "  plt.plot(hist['accuracy'])\n",
        "  plt.plot(hist['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.savefig(dir)\n",
        "  plt.clf()\n",
        "  \n",
        "def plot_loss(model,dir):\n",
        "  \n",
        "  plt.plot(hist['loss'])\n",
        "  plt.plot(hist['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.savefig(dir)\n",
        "  plt.clf()\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "da-vTBMduj7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "XZFEWyce97ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = datetime.now() # used to print time taken to run all experiments at end.\n",
        "\n",
        "# loop through all the models\n",
        "\n",
        "for model in models:\n",
        "# initonlizing model and batch size\n",
        "  model_name = model\n",
        "  feature_extractor = models.get(model)[0]\n",
        "  IMAGE_SIZE = models.get(model)[1]\n",
        "  \n",
        "\n",
        "  # loop through all the batch_sizes for each of the models\n",
        "  for BATCH_SIZE in BATCH_SIZE_LIST:\n",
        "    \n",
        "    BATCH_SIZE = int(BATCH_SIZE)\n",
        "\n",
        "    # load the data\n",
        "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        train_path,\n",
        "        label_mode=\"categorical\",\n",
        "        seed=123,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        batch_size=1)\n",
        "    \n",
        "    class_names = tuple(train_ds.class_names)\n",
        "    train_size = train_ds.cardinality().numpy()\n",
        "    train_ds = train_ds.unbatch().batch(int(BATCH_SIZE))\n",
        "    train_ds = train_ds.repeat()\n",
        "\n",
        "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        valid_path,\n",
        "        label_mode=\"categorical\",\n",
        "        seed=123,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        batch_size=1)\n",
        "    valid_size = val_ds.cardinality().numpy()\n",
        "    val_ds = val_ds.unbatch().batch(int(BATCH_SIZE)) \n",
        "\n",
        "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        test_path,\n",
        "        label_mode=\"categorical\",\n",
        "        seed=123,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        batch_size=1)\n",
        "    \n",
        "\n",
        "    # normalization and data augmentation\n",
        "    normalization_layer = tf.keras.layers.Rescaling(1. / 255)\n",
        "    preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
        "     \n",
        "    preprocessing_model.add(\n",
        "          tf.keras.layers.RandomRotation(40))\n",
        "    preprocessing_model.add(\n",
        "        tf.keras.layers.RandomTranslation(0, 0.2))\n",
        "    preprocessing_model.add(\n",
        "        tf.keras.layers.RandomTranslation(0.2, 0))\n",
        "    preprocessing_model.add(\n",
        "        tf.keras.layers.RandomZoom(0.2, 0.2))\n",
        "    preprocessing_model.add(\n",
        "        tf.keras.layers.RandomFlip(mode=\"horizontal\"))\n",
        "    preprocessing_model.add(\n",
        "        tf.keras.layers.RandomFlip(mode=\"vertical\"))\n",
        "\n",
        "    train_ds = train_ds.map(lambda images, labels:\n",
        "                        (preprocessing_model(images), labels))\n",
        "    val_ds = val_ds.map(lambda images, labels:\n",
        "                      (normalization_layer(images), labels))\n",
        "    test_ds = test_ds.map(lambda images, labels:\n",
        "                      (normalization_layer(images), labels))\n",
        "\n",
        "\n",
        "    # build the model\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(feature_extractor, trainable=False), # Here model is being downloaded\n",
        "    tf.keras.layers.Dropout(rate=0.1),\n",
        "    tf.keras.layers.Dense(len(class_names),\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "    ])\n",
        "    model.build((None,)+IMAGE_SIZE+(3,))\n",
        "    model.summary() \n",
        "    \n",
        "    # compile model\n",
        "    model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9), \n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    # Saving best model settings\n",
        "    SaveModelDir= f\"experiments/{model_name}/exp_for_{str(BATCH_SIZE)}_BatchSize\"\n",
        "    checkpoint_path = SaveModelDir+\"/cp.ckpt\"\n",
        "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "    metric = 'accuracy'\n",
        "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor=metric, \n",
        "                                                   save_weights_only=False, save_best_only = True, verbose=1)\n",
        "    # Save complete Model\n",
        "    model.save(SaveModelDir+f\"/model_for_{str(BATCH_SIZE)}_BatchSize\")\n",
        "\n",
        "\n",
        "    ############################################################################\n",
        "    # start timer for training \n",
        "    start_time = datetime.now()\n",
        "\n",
        "    steps_per_epoch = train_size // int(BATCH_SIZE)\n",
        "    validation_steps = valid_size // int(BATCH_SIZE)\n",
        "\n",
        "    hist = model.fit(\n",
        "      train_ds,\n",
        "      epochs=EPOCHS, steps_per_epoch=steps_per_epoch,\n",
        "      validation_data=val_ds,\n",
        "      validation_steps=validation_steps,\n",
        "      callbacks = [cp_callback]\n",
        "      ).history\n",
        "\n",
        "    end_time = datetime.now() # end timer\n",
        "\n",
        "    f = open(SaveModelDir+f\"/time_to_train_for_{BATCH_SIZE}_model.txt\", \"x\")\n",
        "    f.write('Duration: {}'.format(end_time - start_time))\n",
        "    f.close() \n",
        "    ############################################################################\n",
        "\n",
        "    # plot acc\n",
        "    graph_path = SaveModelDir+'/model_acc.png'\n",
        "    plot_acc(hist,graph_path)\n",
        "\n",
        "    # plot loss\n",
        "    graph_path = SaveModelDir+'/model_loss.png'\n",
        "    plot_loss(hist,graph_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Get metracis for val_ds \n",
        "    y_pred = []  \n",
        "    y_true = []\n",
        "\n",
        "    for image_batch, label_batch in val_ds:   \n",
        "      y_true.append(label_batch)\n",
        "      preds = model.predict(image_batch)\n",
        "      y_pred.append(np.argmax(preds, axis = - 1))\n",
        "    \n",
        "    correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
        "    predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
        "    # Un-One-hot encode the correct labels\n",
        "    correct_labels_tonums = np.argmax(correct_labels,axis=1)\n",
        "\n",
        "    cm = confusion_matrix(correct_labels_tonums, predicted_labels)\n",
        "    fig = plt.figure(figsize = (8,8))\n",
        "    ax1 = fig.add_subplot(1,1,1)\n",
        "    sns.set(font_scale=1.4) #for label size\n",
        "    sns.heatmap(cm, annot=True, annot_kws={\"size\": 12},\n",
        "      cbar = False, cmap='Purples');\n",
        "    ax1.set_ylabel('True Values',fontsize=14)\n",
        "    ax1.set_xlabel('Predicted Values',fontsize=14)\n",
        "    plt.savefig(SaveModelDir+'/con_matrx_val_ds.png')\n",
        "    plt.clf()\n",
        "\n",
        "    loss, acc = model.evaluate(val_ds, verbose=2)\n",
        "    f = open(SaveModelDir+f\"/VAL_DS_{BATCH_SIZE}_model.txt\", \"x\")\n",
        "    f.write(classification_report(correct_labels_tonums,predicted_labels))\n",
        "    f.write(\"\\n model accuracy on val_ds {:5.2f}%\".format(100 * acc))\n",
        "    f.close() \n",
        "\n",
        "\n",
        "\n",
        "    # Get metracis for test_ds\n",
        "    y_pred = []  \n",
        "    y_true = [] \n",
        "\n",
        "    for image_batch, label_batch in test_ds:   \n",
        "      y_true.append(label_batch)\n",
        "      preds = model.predict(image_batch)\n",
        "      y_pred.append(np.argmax(preds, axis = - 1))\n",
        "\n",
        "    # convert the true and predicted labels into tensors\n",
        "    correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
        "    predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
        "\n",
        "    # Un-One-hot encode the correct labels\n",
        "    correct_labels_tonums = np.argmax(correct_labels,axis=1)\n",
        "\n",
        "    \n",
        "    cm = confusion_matrix(correct_labels_tonums, predicted_labels)\n",
        "    fig = plt.figure(figsize = (8,8))\n",
        "    ax1 = fig.add_subplot(1,1,1)\n",
        "    sns.set(font_scale=1.4) #for label size\n",
        "    sns.heatmap(cm, annot=True, annot_kws={\"size\": 12},\n",
        "      cbar = False, cmap='Purples');\n",
        "    ax1.set_ylabel('True Values',fontsize=14)\n",
        "    ax1.set_xlabel('Predicted Values',fontsize=14)\n",
        "    plt.savefig(SaveModelDir+'/con_matrx_test_ds.png')\n",
        "    plt.clf()\n",
        "\n",
        "\n",
        "    loss, acc = model.evaluate(test_ds, verbose=2)\n",
        "    f = open(SaveModelDir+f\"/TEST_DS_{BATCH_SIZE}_model.txt\", \"x\")\n",
        "    f.write(classification_report(correct_labels_tonums,predicted_labels))\n",
        "    f.write(\"\\n model accuracy on test_ds {:5.2f}%\".format(100 * acc))\n",
        "    f.close() \n",
        "\n",
        "\n",
        "end_time = datetime.now() # end timer\n",
        "\n",
        "print(\"training 3 epochs of this script took : \" + 'Duration: {}'.format(end_time - start_time))"
      ],
      "metadata": {
        "id": "eXientSWzq80"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}